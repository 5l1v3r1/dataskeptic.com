{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import snappy\n",
    "import pyarrow\n",
    "import sklearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets, linear_model\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from numpy import convolve\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/elasticsearch/connection/http_urllib3.py:54: UserWarning: Connecting to search-test-vu2fwve5ykzm5tsjkut5q4idum.us-east-1.es.amazonaws.com using SSL with verify_certs=False is insecure.\n",
      "  'Connecting to %s using SSL with verify_certs=False is insecure.' % host)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_crawls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f89d1b89b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0melastic_search_conn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m443\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#elastic_search_conn.indices.delete(index='github_jobs', ignore=[400, 404])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mcrawls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_crawls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmysql_conn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmysql_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrawls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_crawls' is not defined"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = json.load(open('../config/config.json', 'r'))\n",
    "    index_name = 'github_jobs'\n",
    "    user = config['dev']['mysql']['user']\n",
    "    password = config['dev']['mysql']['password']\n",
    "    host = config['dev']['mysql']['host']\n",
    "    port = config['dev']['mysql']['port']\n",
    "    dbname = config['dev']['mysql']['dbname']\n",
    "    endpoint = config['dev']['elastic_search_endpoint']\n",
    "    template = \"mysql+pymysql://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "    connection_string = template.format(user=user, password=password, host=host, port=port, dbname=dbname)\n",
    "    mysql_conn = sqlalchemy.create_engine(connection_string, pool_size=1)\n",
    "    elastic_search_conn = Elasticsearch(endpoint, port=443)\n",
    "    #elastic_search_conn.indices.delete(index='github_jobs', ignore=[400, 404])\n",
    "    crawls = get_crawls(mysql_conn)\n",
    "    jobs = get_jobs(mysql_conn, crawls)\n",
    "    for job in jobs:\n",
    "        ca = pd.to_datetime(job['created_at'])\n",
    "        job['created_at'] = ca\n",
    "        result2 = elastic_search_conn.index(index_name, 'jobs', job, id=job['id'])  \n",
    "        if result2['_shards']['successful']!=1:\n",
    "            print(\"Failed to insert\")\n",
    "            sys.exit(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crawls(mysql_conn):\n",
    "    query = \"\"\"\n",
    "        SELECT location, description\n",
    "        FROM github_job_crawl_description\n",
    "        CROSS JOIN github_job_crawl_location\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, mysql_conn)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawls = get_crawls(mysql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.indeed.com/jobs?q={description}&l={location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(mysql_conn, crawls):\n",
    "    jobs = []\n",
    "    for r in range(crawls.shape[0]):\n",
    "        row = crawls.iloc[r]\n",
    "        description = row['description']\n",
    "        location = row['location']\n",
    "        t = \"https://jobs.github.com/positions.json?description={description}&location={location}\"\n",
    "        url = t.format(description=description, location=location)\n",
    "        r = requests.get(url)\n",
    "        s = r.content.decode('utf-8')\n",
    "        o = json.loads(s)\n",
    "        jobs.extend(o)\n",
    "        time.sleep(1)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = crawls.iloc[0]\n",
    "description = row['description']\n",
    "location = row['location']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/jobs?q=python&l=new york'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"https://www.indeed.com/jobs?q={description}&l={location}\"\n",
    "url = t.format(description=description, location=location)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "company = []\n",
    "location = []\n",
    "city = []\n",
    "jd = []\n",
    "for each in all_matches:\n",
    "    time.sleep(1)\n",
    "    jd_url= 'http://www.indeed.com/m/'+each['href']\n",
    "    jd_page = urlopen(jd_url)\n",
    "    jd_soup = BeautifulSoup(jd_page, 'html.parser')\n",
    "    jd_desc = jd_soup.findAll('div',attrs={'id':['desc']}) ## find the structure like: <div id=\"desc\"></>\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location       new york\n",
       "description      python\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawls.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawls = get_crawls(mysql_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = get_jobs(mysql_conn, crawls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(mysql_conn, crawls):\n",
    "    jobs = []\n",
    "    for r in range(crawls.shape[0]):\n",
    "        row = crawls.iloc[r]\n",
    "        description = row['description']\n",
    "        location = row['location']\n",
    "        t = \"https://jobs.github.com/positions.json?description={description}&location={location}\"\n",
    "        url = t.format(description=description, location=location)\n",
    "        r = requests.get(url)\n",
    "        s = r.content.decode('utf-8')\n",
    "        o = json.loads(s)\n",
    "        jobs.extend(o)\n",
    "        time.sleep(1)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location       new york\n",
       "description      python\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawls.iloc[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test single city boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crawls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d9f09367c1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrawls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crawls' is not defined"
     ]
    }
   ],
   "source": [
    "row = crawls.iloc[0]\n",
    "description = row['description']\n",
    "location = row['location']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'description' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-495b5ec7fd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.indeed.com/jobs?q={description}&l={location}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'description' is not defined"
     ]
    }
   ],
   "source": [
    "t = \"https://www.indeed.com/jobs?q={description}&l={location}\"\n",
    "url = t.format(description=description, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.com/jobs?q=python&l=new york'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python Developer',\n",
       " 'Software Engineer - Python',\n",
       " 'Full-Stack Software Developer',\n",
       " 'BIM Coordinator',\n",
       " 'Computer Science Teacher',\n",
       " 'Backend Python Developer',\n",
       " 'Python Developer',\n",
       " 'Full Stack Software Engineer',\n",
       " 'Data Analyst',\n",
       " 'Junior Full Stack Software Engineer, Back End Focus',\n",
       " 'Full Stack Software Engineer',\n",
       " 'Python Developer',\n",
       " 'Python Developer with Hadoop',\n",
       " 'Full Stack Engineer',\n",
       " 'Computer Engineer III (FPGA)',\n",
       " 'Fullstack Python Developer']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobs.append(a['title'])\n",
    "    return(jobs)\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KPMG',\n",
       " 'Elevano',\n",
       " 'Assured Information Security, Inc. (AIS)',\n",
       " 'PDACT LLC',\n",
       " 'SymbaSync',\n",
       " 'MakerBot',\n",
       " 'Ankura Consulting Group',\n",
       " 'Sophilabs',\n",
       " 'Phreesia',\n",
       " 'SmartAsset',\n",
       " 'Bloomberg',\n",
       " 'MakerBot',\n",
       " 'GP Energy Management',\n",
       " 'The Metro Group, Inc.',\n",
       " 'Covet Time, Inc.',\n",
       " 'BlindData']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class':'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)\n",
    "\n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boston, MA',\n",
       " 'Waltham, MA',\n",
       " 'Boston, MA',\n",
       " 'Lexington, MA 02420',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA 02111 (Central area)',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA 02109 (Central area)',\n",
       " 'Boston, MA',\n",
       " 'Boston, MA',\n",
       " 'Lynn, MA',\n",
       " 'Boston, MA']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blockchain APIs (e.g., Python wrappers for Bitcoin/Ethereum/Litecoin/Bitcoin Cash/Ripple). As a team member, your primary responsibility will be to focus on...',\n",
       " 'Python & Django with a PostgreSQL database, running on an Amazon AWS infrastructure. A full stack developer on the Triib platform should be experienced working...',\n",
       " 'Experience developing and debugging with languages such as JavaScript, Python, or Ruby. Signature Orthodontics, Inc., a stealth mode startup, is recognized as a...',\n",
       " 'Proficiency with C/C++, Linux build systems, standard software engineering practices (version control, bug tracking, unit testing), and at least one of Python...',\n",
       " 'Strong experience with core Python development. Experience with any python technologies including ones such as (NumPy, SciPy, Pandas, Tensorflow)....',\n",
       " 'Python Front End Developer*. Looking for a strong python front end developer (also need a few *CORE PYTHON*....',\n",
       " 'Experience with Python scripting. Seeking person with Data Processing skills for quantitative market research....',\n",
       " 'React.js and Python development:. React.js and Python (full stack; Our client is taking on the challenge of applying Artificial Intelligence to medicine....',\n",
       " 'Blockchain APIs (e.g., Python wrappers for Bitcoin/Ethereum/Litecoin/Bitcoin Cash/Ripple). As a team member, your primary responsibility will be to focus on...',\n",
       " 'You have 2+ years of backend experience, preferably but not necessarily in Python. They split up into 2 groups-- one doing customer facing modeling in the...',\n",
       " 'Experience in the programming language python preferred. 403060 IT Support Associate I....',\n",
       " 'Scala or Java preferred, Swift/C#/C++ acceptable, Python helpful but not required. About the Role....',\n",
       " 'Scala preferred, Java/C#/C++ acceptable, Python helpful. About the Role....',\n",
       " \"(strong Python, SQL's, MySQL, PostgreSQL, MongoDB). (strong Python, SQL's, MySQL, PostgreSQL, MongoDB) needed in *Boston, MA*. Hi,....\",\n",
       " 'O Microsoft PowerShell, Python or other scripting languages. When you join Eastern Bank, you join the largest and oldest mutual bank in the country....',\n",
       " 'EXPERIENCED Python developer – 5 years*. - Prove your experience with Python Web Framework*. - Problem solver need only apply*....']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'summary'})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 10\n",
    "city_set = crawls['location'].drop_duplicates().tolist()\n",
    "columns = ['city','job_title', 'company_name', 'location', 'summary']\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bs4/__init__.py:146: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "for city in city_set:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        time.sleep(2)\n",
    "        page = requests.get('http://www.indeed.com/jobs?q=data&l=' + str(city) + '&start=' + str(start))\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser', from_encoding='utf-8')\n",
    "        for div in soup.find_all(name='div', attrs={'class':'row'}): \n",
    "        #specifying row num for index of job posting in dataframe\n",
    "            num = (len(sample_df) + 1) \n",
    "            #creating an empty list to hold the data for each posting\n",
    "            job_post = [] \n",
    "            #append city name\n",
    "            job_post.append(city) \n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "                  job_post.append(a['title']) \n",
    "            #grabbing company name\n",
    "            company = div.find_all(name='span', attrs={'class':'company'}) \n",
    "            if len(company) > 0: \n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip()) \n",
    "            else: \n",
    "                sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "                for span in sec_try:\n",
    "                    job_post.append(span.text) \n",
    "            #grabbing location name\n",
    "            c = div.findAll('span', attrs={'class': 'location'}) \n",
    "            for span in c: \n",
    "                job_post.append(span.text) \n",
    "            #grabbing summary text\n",
    "            d = div.findAll('span', attrs={'class': 'summary'}) \n",
    "            for span in d:\n",
    "                job_post.append(span.text.strip())\n",
    "            sample_df.loc[num] = job_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data & Analytics Team. Data & Analytics team culture:. As a Data Scientist at AbleTo, you will work in a uniquely cross-functional capacity, helping teams...'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class':'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)\n",
    "\n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AbleTo, Inc.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Data &amp; Analytics Team. Data &amp; Analytics team culture:. As a Data Scientist at AbleTo, you will work in a uniquely cross-functional capacity, helping teams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new york</td>\n",
       "      <td>Image Scientist - Software Engineer</td>\n",
       "      <td>Harris Corporation</td>\n",
       "      <td>Rochester, NY</td>\n",
       "      <td>Image Scientist - Software Engineer. Performs image system simulations to produce realistic test data to support system validation and testing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new york</td>\n",
       "      <td>Senior Data Scientist - BLAW</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Our data scientists and engineers work closely with product managers, content team members and market strategists....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Darwin Recruitment</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Together we are searching for 2 Data Scientists to join an expanding team. Responsibilities Data Analysis &amp; Data Modelling Implementing various Algorithms to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist, Growth Insights</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>You’re capable of mentoring more junior data scientist to set them up for success. We are looking for a Data Scientist to join the band and help drive a data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist, Data &amp; Analytics</td>\n",
       "      <td>MLB Advanced Media</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>Data Scientist, Data &amp; Analytics. MLBAM is looking for a Data Scientist to join its Data &amp; Analytics team in our New York City office....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Collective[i]</td>\n",
       "      <td>New York State</td>\n",
       "      <td>We are looking for a Data Scientist with a strong computational background (complimented by Statistics/Math/Algorithmic expertise), experience dealing with Big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist, Analytics (Instagram)</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>The Data Scientist Analytics role has work across the following four areas:. We’re looking for Data Scientists to work on our core and business products across...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pager</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Participate as a member of interdisciplinary squads that includes data engineers, data scientists software engineers and business leaders....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>We want data scientists who know how to use their knowledge and skill with data and statistics to create real, actionable product insights....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist (Product)</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>We are looking for a Data Scientist to join the band and help drive a data-first culture across Spotify. As a Data Scientist, our mission is to turn terabytes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>new york</td>\n",
       "      <td>CoinFund is hiring</td>\n",
       "      <td>CoinFund</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>Roles include but are not limited to engineers, analysts, operations manager, data scientists, account managers, growth hackers, content creators, systems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kasisto</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3+ years professional experience with data engineering, data science, and/or database administration. We are looking for an experienced data engineer/scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Foursquare</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3+ years work experience as a data scientist or in analytics, working with big datasets. Familiarity with Foursquare or location data and an ability to clearly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shore Group Associates, LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>We are looking for data scientists who are not only interested in plugging data into a model, but also understanding the data like the back of their hand....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>new york</td>\n",
       "      <td>Data Scientist - Fixed Income Real-Time Pricing</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Experience with handling large scale data sets. As a Data Scientist you will help lead our research efforts as well as develop production-quality systems to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Data Scientist with SQL and R Programming</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Burbank, CA</td>\n",
       "      <td>At least 8-10 years of overall analytics and data science experience. At least 5-8 years of experience in hard core Data Science projects....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Postdoctoral Scientist (Flow Cytometry)</td>\n",
       "      <td>CEDARS-SINAI</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Analyzes and interprets data. The Flow Cytometry Core of Cedars-Sinai looking for a Postdoctoral Scientist to join its team....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Machine Shop Technician/Apprentice</td>\n",
       "      <td>RadiaBeam Technologies, LLC</td>\n",
       "      <td>Santa Monica, CA 90404</td>\n",
       "      <td>Basic data entry on a PC. Our staff currently consists of approximately 50 scientists, engineers, technicians and machinists....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>FabFitFun</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Financial transactional data. Experience with consumer/consumer-facing data. Utilize Jupyter Notebook to create, test, and display data cleaning, data science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Machine Learning Engineer - LA</td>\n",
       "      <td>SymbaSync</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>By creating your profile on SymbaSync you will be eligible for this job opportunity, and all others being hired for on the site. Our client is looking for an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Movio</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>2+ years’ experience as a Data Analyst or Business Data Analyst. Implement new data analysis methodologies. Develop and implement data analyses, data collection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Universal Music Group</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>Universal Music Group is looking for a Data Scientist to join our in-house Data Science R&amp;D team, working across prediction, segmentation, price optimization,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Factual</td>\n",
       "      <td>Los Angeles, CA 90067</td>\n",
       "      <td>Our Data team is seeking an Associate Data Scientist to help us ensure we deliver the highest quality Global Places product on the market....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hulu</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>We are looking for data scientists who are passionate about using data to drive strategy and product recommendations....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Mathematical Statistician</td>\n",
       "      <td>Tax</td>\n",
       "      <td>Los Angeles, CA 90048</td>\n",
       "      <td>Use SAS to apply the IRS sampling methodology set forth in IRM 42(18) at a global tax firm. Compensation DOE. Job Type: Full-time Salary: $75,000.00 to $150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tala</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>We are looking for a Data Scientist interested in solving one of the world's largest problems:. Leverage a unique, diverse, and deep data set to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CannaData Solutions</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>CannaData Solutions is looking to add a Data Scientist with a diverse toolkit to their development team. Ability to explain data analysis to a non-technical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>IT Business Data Analysis Intern, Corporate – Summer 2018</td>\n",
       "      <td>Sony Pictures Entertainment Inc.</td>\n",
       "      <td>Culver City, CA 90232</td>\n",
       "      <td>Conduct data analysis on Identity data within SPE. IT Business Data Analysis Intern, Corporate – Summer 2018. The IT Business Data Analyst Intern will join the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>Systems Engr Support Analyst (Early Career)</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>El Segundo, CA 90245</td>\n",
       "      <td>Skilled scientists and thinkers. Support Integrated Product Teams throughout the product life cycle, integrating data across tools and providing analyses from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Research Associate</td>\n",
       "      <td>RR Donnelley</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Information management and document distribution in virtual data rooms, like Microsoft SharePoint. Secondary research for financial and statistical data on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Document Control Specialist II</td>\n",
       "      <td>Intersect ENT</td>\n",
       "      <td>Menlo Park, CA 94025</td>\n",
       "      <td>P UR P O S E OF JO B : Pe rf o r ms D ocu m ent C on tr o l and Rec o r d C o n t r ol a c t i v i ti e s , and p r o v i des ad m i n i s t r a ti v e s uppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Data Entry Clerk</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>1-2 years Data Entry Experience. Insight Global is looking for a Data Entry Clerk to sit onsite at one of our clients in Palo Alto, Ca....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Jr. Business Analyst Intern</td>\n",
       "      <td>City of Palo Alto</td>\n",
       "      <td>Palo Alto, CA 94303 (Duveneck-Saint Francis area)</td>\n",
       "      <td>Candidate will be responsible for business requirements gathering, data flow diagramming, presentations, and develop training manuals and training videos....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Data Analytics Intern</td>\n",
       "      <td>CarDash</td>\n",
       "      <td>Menlo Park, CA 94025</td>\n",
       "      <td>Excel data manipulation. Data visualization and reporting. Strong analytical and data skills. You are data driven and analytical....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Reliability Data Analyst</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Strong SQL, comfortable writing queries, data processing scripts, and understanding RDBMS data structures. Able to visualize data effectively....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Analytics Developer/Analyst</td>\n",
       "      <td>Palo Alto Networks</td>\n",
       "      <td>Santa Clara, CA 95054</td>\n",
       "      <td>Develop rich, interactive, visually striking graphics and data visualizations of large amounts of data. Data manipulation and transformation skills....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Junior Informatica Data Analyst</td>\n",
       "      <td>Inter Sources Inc</td>\n",
       "      <td>Fremont, CA</td>\n",
       "      <td>Job Description Hi, We are currently Looking for 8 Junior Informatica Data Analysts Location : Fremont, CA (Preferred Local to Bay Area) Skills Required 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Research Data Analyst</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Stanford, CA 94305</td>\n",
       "      <td>Analyze data processes in documentation. Use system reports and analyses to identify potentially problematic data, make corrections, and determine root cause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Quantitative Researcher, Growth</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Knowledge in data manipulation and analysis (R/SAS/Stata, SQL/Hive). Knowledge in quantitative research methodologies (e.g., survey sampling and design,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Data Management Specialist</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Stanford, CA 94305</td>\n",
       "      <td>Lead the implementation of data standards and common data elements for data collection. Create data dictionaries and libraries that document how data are housed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Data Center Site Engineering Intern</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>The Data Center Site Engineering team is looking for an intern to work at the intersection of the data center and the hardware that fills it....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Santa Clara Valley, CA</td>\n",
       "      <td>Experience with analytical tools supporting data evaluation and reporting, as well as querying large, complex data sets (Splunk, Tableau, SQL, R, etc)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>palo alto</td>\n",
       "      <td>Big Data Opportunities - Lafayette, LA</td>\n",
       "      <td>CGI</td>\n",
       "      <td>Lafayette, CA</td>\n",
       "      <td>Hadoop, Teradata, MPP, Database programming, Understanding of data models.  Collaborate with developers and business users for overall design oversight on Big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>boston</td>\n",
       "      <td>PBM Business Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>United States</td>\n",
       "      <td>We are seeking a PBM Business Analyst in the Washington, DC area. Can work remotely with some travel once every 6 to 8 weeks to Hartford, CT or Richmond, VA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>boston</td>\n",
       "      <td>Technologist - Data Analysis</td>\n",
       "      <td>Liberty Mutual</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Technologist - Data Analysis-92954. Act as a solutions engineer working within modern architectures and frameworks while experimenting with newer technologies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>boston</td>\n",
       "      <td>Principal Data Analyst</td>\n",
       "      <td>Liberty Mutual</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Perform routine data investigations to profile and analyze data sets to address data quality and integrity. Principal Data Analyst-92956....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>boston</td>\n",
       "      <td>Senior Product Manager- Data Products</td>\n",
       "      <td>M.Gemi</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>This Product Manager will be responsible for product development related to data collection, aggregation, derived data products and all related operations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>boston</td>\n",
       "      <td>Entry-Level Business Data Analyst</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>Boston, MA 02110 (Central area)</td>\n",
       "      <td>Highly proficient with data analytics, and experience in data manipulation using a variety of tools. Natural curiosity, and a demonstrated ability to turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>boston</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Burning Glass Technologies</td>\n",
       "      <td>Boston, MA 02110 (Central area)</td>\n",
       "      <td>Running specified queries using Burning Glass’s proprietary labor market database and other published data sources, preparing data for presentation, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>boston</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Allen &amp; Gerritsen</td>\n",
       "      <td>Boston, MA 02210 (South Boston area)</td>\n",
       "      <td>Organize and structure performance related data from a variety of sources (paid media, social platforms, web analytics solutions, 3rd party data providers)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>boston</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>True Fit</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Data visualization experience. Knowledge of data analysis, statistics, mathematical modeling, and/or machine learning....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>boston</td>\n",
       "      <td>Artificial Intelligence Programmer/Data Scientist Internship - remote</td>\n",
       "      <td>Liquid Intelligence</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Be able to write emails properly -- we communicate with global leaders, innovators, investors, entrepreneurs, C-level executives and folks within the IoT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>boston</td>\n",
       "      <td>Survey Programmer &amp; Data Analyst</td>\n",
       "      <td>Kadence International</td>\n",
       "      <td>Boston, MA 02111 (Central area)</td>\n",
       "      <td> jQuery or other javascript framework within data collection system Write specialized macros to extract/ format data....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>boston</td>\n",
       "      <td>Data Science Intern - QuantumBlack</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>You will have the chance to write highly optimised code to advance our internal Data Science toolbox, and you'll develop world-class data science products for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>boston</td>\n",
       "      <td>Data Entry Associate</td>\n",
       "      <td>HMS Holdings</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Compiles data from various sources, verifies data. Ability to maintain confidentiality and handle sensitive data....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>boston</td>\n",
       "      <td>Data Associate</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Amazon is seeking a French Language Data Associate to join our Kindle data team. The French Language Data Associate must have a passion for data, efficiency,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>boston</td>\n",
       "      <td>User Research Data Analyst Intern for mental health startup (non-profit)</td>\n",
       "      <td>Affect Mental Health</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Patient data) to identify trends. Data munging and mining is a thing you’ve done. Ability to story tell and visualize data coherently (d3, ggplot2, etc.)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>boston</td>\n",
       "      <td>Sr. Healthcare Data Analyst - Boston</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td>Conduct data exploration, solve data problems, and execute algorithmic data processing using SQL. Provide specifications to Data Warehouse team for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>boston</td>\n",
       "      <td>SQL Database Administrator &amp; Reporting Analyst , 40 hours, Day Shift</td>\n",
       "      <td>New England Baptist Hospital</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Support data migration projects, conversion, and product upgrades. Will work closely with development and infrastructure staff to maintain secure access to data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  \\\n",
       "1    new york      \n",
       "2    new york      \n",
       "3    new york      \n",
       "4    new york      \n",
       "5    new york      \n",
       "6    new york      \n",
       "7    new york      \n",
       "8    new york      \n",
       "9    new york      \n",
       "10   new york      \n",
       "11   new york      \n",
       "12   new york      \n",
       "13   new york      \n",
       "14   new york      \n",
       "15   new york      \n",
       "16   new york      \n",
       "17   los angeles   \n",
       "18   los angeles   \n",
       "19   los angeles   \n",
       "20   los angeles   \n",
       "21   los angeles   \n",
       "22   los angeles   \n",
       "23   los angeles   \n",
       "24   los angeles   \n",
       "25   los angeles   \n",
       "26   los angeles   \n",
       "27   los angeles   \n",
       "28   los angeles   \n",
       "29   los angeles   \n",
       "30   los angeles   \n",
       "..           ...   \n",
       "547  palo alto     \n",
       "548  palo alto     \n",
       "549  palo alto     \n",
       "550  palo alto     \n",
       "551  palo alto     \n",
       "552  palo alto     \n",
       "553  palo alto     \n",
       "554  palo alto     \n",
       "555  palo alto     \n",
       "556  palo alto     \n",
       "557  palo alto     \n",
       "558  palo alto     \n",
       "559  palo alto     \n",
       "560  palo alto     \n",
       "561  boston        \n",
       "562  boston        \n",
       "563  boston        \n",
       "564  boston        \n",
       "565  boston        \n",
       "566  boston        \n",
       "567  boston        \n",
       "568  boston        \n",
       "569  boston        \n",
       "570  boston        \n",
       "571  boston        \n",
       "572  boston        \n",
       "573  boston        \n",
       "574  boston        \n",
       "575  boston        \n",
       "576  boston        \n",
       "\n",
       "                                                                    job_title  \\\n",
       "1    Data Scientist                                                             \n",
       "2    Image Scientist - Software Engineer                                        \n",
       "3    Senior Data Scientist - BLAW                                               \n",
       "4    Data Scientist                                                             \n",
       "5    Data Scientist, Growth Insights                                            \n",
       "6    Data Scientist, Data & Analytics                                           \n",
       "7    Data Scientist                                                             \n",
       "8    Data Scientist, Analytics (Instagram)                                      \n",
       "9    Data Analyst                                                               \n",
       "10   Data Scientist                                                             \n",
       "11   Data Scientist (Product)                                                   \n",
       "12   CoinFund is hiring                                                         \n",
       "13   Data Scientist                                                             \n",
       "14   Data Scientist                                                             \n",
       "15   Data Scientist                                                             \n",
       "16   Data Scientist - Fixed Income Real-Time Pricing                            \n",
       "17   Data Scientist with SQL and R Programming                                  \n",
       "18   Postdoctoral Scientist (Flow Cytometry)                                    \n",
       "19   Machine Shop Technician/Apprentice                                         \n",
       "20   Junior Data Scientist                                                      \n",
       "21   Machine Learning Engineer - LA                                             \n",
       "22   Data Analyst                                                               \n",
       "23   Data Scientist                                                             \n",
       "24   Associate Data Scientist                                                   \n",
       "25   Data Scientist                                                             \n",
       "26   Mathematical Statistician                                                  \n",
       "27   Data Scientist                                                             \n",
       "28   Data Scientist                                                             \n",
       "29   IT Business Data Analysis Intern, Corporate – Summer 2018                  \n",
       "30   Systems Engr Support Analyst (Early Career)                                \n",
       "..                                           ...                                \n",
       "547  Research Associate                                                         \n",
       "548  Document Control Specialist II                                             \n",
       "549  Data Entry Clerk                                                           \n",
       "550  Jr. Business Analyst Intern                                                \n",
       "551  Data Analytics Intern                                                      \n",
       "552  Reliability Data Analyst                                                   \n",
       "553  Analytics Developer/Analyst                                                \n",
       "554  Junior Informatica Data Analyst                                            \n",
       "555  Research Data Analyst                                                      \n",
       "556  Quantitative Researcher, Growth                                            \n",
       "557  Data Management Specialist                                                 \n",
       "558  Data Center Site Engineering Intern                                        \n",
       "559  Data Analyst                                                               \n",
       "560  Big Data Opportunities - Lafayette, LA                                     \n",
       "561  PBM Business Analyst                                                       \n",
       "562  Technologist - Data Analysis                                               \n",
       "563  Principal Data Analyst                                                     \n",
       "564  Senior Product Manager- Data Products                                      \n",
       "565  Entry-Level Business Data Analyst                                          \n",
       "566  Research Analyst                                                           \n",
       "567  Analyst                                                                    \n",
       "568  Data Analyst                                                               \n",
       "569  Artificial Intelligence Programmer/Data Scientist Internship - remote      \n",
       "570  Survey Programmer & Data Analyst                                           \n",
       "571  Data Science Intern - QuantumBlack                                         \n",
       "572  Data Entry Associate                                                       \n",
       "573  Data Associate                                                             \n",
       "574  User Research Data Analyst Intern for mental health startup (non-profit)   \n",
       "575  Sr. Healthcare Data Analyst - Boston                                       \n",
       "576  SQL Database Administrator & Reporting Analyst , 40 hours, Day Shift       \n",
       "\n",
       "                         company_name  \\\n",
       "1    AbleTo, Inc.                       \n",
       "2    Harris Corporation                 \n",
       "3    Bloomberg                          \n",
       "4    Darwin Recruitment                 \n",
       "5    Spotify                            \n",
       "6    MLB Advanced Media                 \n",
       "7    Collective[i]                      \n",
       "8    Facebook                           \n",
       "9    Pager                              \n",
       "10   Tumblr                             \n",
       "11   Spotify                            \n",
       "12   CoinFund                           \n",
       "13   Kasisto                            \n",
       "14   Foursquare                         \n",
       "15   Shore Group Associates, LLC        \n",
       "16   Bloomberg                          \n",
       "17   Cognizant                          \n",
       "18   CEDARS-SINAI                       \n",
       "19   RadiaBeam Technologies, LLC        \n",
       "20   FabFitFun                          \n",
       "21   SymbaSync                          \n",
       "22   Movio                              \n",
       "23   Universal Music Group              \n",
       "24   Factual                            \n",
       "25   Hulu                               \n",
       "26   Tax                                \n",
       "27   Tala                               \n",
       "28   CannaData Solutions                \n",
       "29   Sony Pictures Entertainment Inc.   \n",
       "30   BOEING                             \n",
       "..      ...                             \n",
       "547  RR Donnelley                       \n",
       "548  Intersect ENT                      \n",
       "549  Insight Global                     \n",
       "550  City of Palo Alto                  \n",
       "551  CarDash                            \n",
       "552  Tesla                              \n",
       "553  Palo Alto Networks                 \n",
       "554  Inter Sources Inc                  \n",
       "555  Stanford University                \n",
       "556  Facebook                           \n",
       "557  Stanford University                \n",
       "558  Facebook                           \n",
       "559  Apple                              \n",
       "560  CGI                                \n",
       "561  Accenture                          \n",
       "562  Liberty Mutual                     \n",
       "563  Liberty Mutual                     \n",
       "564  M.Gemi                             \n",
       "565  DraftKings                         \n",
       "566  Burning Glass Technologies         \n",
       "567  Allen & Gerritsen                  \n",
       "568  True Fit                           \n",
       "569  Liquid Intelligence                \n",
       "570  Kadence International              \n",
       "571  McKinsey & Company                 \n",
       "572  HMS Holdings                       \n",
       "573  Amazon.com                         \n",
       "574  Affect Mental Health               \n",
       "575  UnitedHealth Group                 \n",
       "576  New England Baptist Hospital       \n",
       "\n",
       "                                              location  \\\n",
       "1    New York, NY                                        \n",
       "2    Rochester, NY                                       \n",
       "3    New York, NY                                        \n",
       "4    New York, NY                                        \n",
       "5    New York, NY 10011 (Chelsea area)                   \n",
       "6    New York, NY 10011 (Chelsea area)                   \n",
       "7    New York State                                      \n",
       "8    New York, NY                                        \n",
       "9    New York, NY                                        \n",
       "10   New York, NY                                        \n",
       "11   New York, NY 10011 (Chelsea area)                   \n",
       "12   Brooklyn, NY                                        \n",
       "13   New York, NY                                        \n",
       "14   New York, NY                                        \n",
       "15   New York, NY                                        \n",
       "16   New York, NY                                        \n",
       "17   Burbank, CA                                         \n",
       "18   Los Angeles, CA                                     \n",
       "19   Santa Monica, CA 90404                              \n",
       "20   Los Angeles, CA                                     \n",
       "21   Los Angeles, CA                                     \n",
       "22   Los Angeles, CA                                     \n",
       "23   Santa Monica, CA                                    \n",
       "24   Los Angeles, CA 90067                               \n",
       "25   Santa Monica, CA                                    \n",
       "26   Los Angeles, CA 90048                               \n",
       "27   Santa Monica, CA                                    \n",
       "28   Los Angeles, CA                                     \n",
       "29   Culver City, CA 90232                               \n",
       "30   El Segundo, CA 90245                                \n",
       "..                    ...                                \n",
       "547  Menlo Park, CA                                      \n",
       "548  Menlo Park, CA 94025                                \n",
       "549  Palo Alto, CA                                       \n",
       "550  Palo Alto, CA 94303 (Duveneck-Saint Francis area)   \n",
       "551  Menlo Park, CA 94025                                \n",
       "552  Palo Alto, CA                                       \n",
       "553  Santa Clara, CA 95054                               \n",
       "554  Fremont, CA                                         \n",
       "555  Stanford, CA 94305                                  \n",
       "556  Menlo Park, CA                                      \n",
       "557  Stanford, CA 94305                                  \n",
       "558  Menlo Park, CA                                      \n",
       "559  Santa Clara Valley, CA                              \n",
       "560  Lafayette, CA                                       \n",
       "561  United States                                       \n",
       "562  Boston, MA                                          \n",
       "563  Boston, MA                                          \n",
       "564  Boston, MA                                          \n",
       "565  Boston, MA 02110 (Central area)                     \n",
       "566  Boston, MA 02110 (Central area)                     \n",
       "567  Boston, MA 02210 (South Boston area)                \n",
       "568  Boston, MA                                          \n",
       "569  Boston, MA                                          \n",
       "570  Boston, MA 02111 (Central area)                     \n",
       "571  Boston, MA                                          \n",
       "572  Boston, MA                                          \n",
       "573  Boston, MA                                          \n",
       "574  Boston, MA                                          \n",
       "575  Boston, MA 02298                                    \n",
       "576  Boston, MA                                          \n",
       "\n",
       "                                                                                                                                                                 summary  \n",
       "1    Data & Analytics Team. Data & Analytics team culture:. As a Data Scientist at AbleTo, you will work in a uniquely cross-functional capacity, helping teams...        \n",
       "2    Image Scientist - Software Engineer. Performs image system simulations to produce realistic test data to support system validation and testing....                   \n",
       "3    Our data scientists and engineers work closely with product managers, content team members and market strategists....                                                \n",
       "4    Together we are searching for 2 Data Scientists to join an expanding team. Responsibilities Data Analysis & Data Modelling Implementing various Algorithms to...     \n",
       "5    You’re capable of mentoring more junior data scientist to set them up for success. We are looking for a Data Scientist to join the band and help drive a data...     \n",
       "6    Data Scientist, Data & Analytics. MLBAM is looking for a Data Scientist to join its Data & Analytics team in our New York City office....                            \n",
       "7    We are looking for a Data Scientist with a strong computational background (complimented by Statistics/Math/Algorithmic expertise), experience dealing with Big...   \n",
       "8    The Data Scientist Analytics role has work across the following four areas:. We’re looking for Data Scientists to work on our core and business products across...   \n",
       "9    Participate as a member of interdisciplinary squads that includes data engineers, data scientists software engineers and business leaders....                        \n",
       "10   We want data scientists who know how to use their knowledge and skill with data and statistics to create real, actionable product insights....                       \n",
       "11   We are looking for a Data Scientist to join the band and help drive a data-first culture across Spotify. As a Data Scientist, our mission is to turn terabytes...    \n",
       "12   Roles include but are not limited to engineers, analysts, operations manager, data scientists, account managers, growth hackers, content creators, systems...        \n",
       "13   3+ years professional experience with data engineering, data science, and/or database administration. We are looking for an experienced data engineer/scientist...   \n",
       "14   3+ years work experience as a data scientist or in analytics, working with big datasets. Familiarity with Foursquare or location data and an ability to clearly...   \n",
       "15   We are looking for data scientists who are not only interested in plugging data into a model, but also understanding the data like the back of their hand....        \n",
       "16   Experience with handling large scale data sets. As a Data Scientist you will help lead our research efforts as well as develop production-quality systems to...      \n",
       "17   At least 8-10 years of overall analytics and data science experience. At least 5-8 years of experience in hard core Data Science projects....                        \n",
       "18   Analyzes and interprets data. The Flow Cytometry Core of Cedars-Sinai looking for a Postdoctoral Scientist to join its team....                                      \n",
       "19   Basic data entry on a PC. Our staff currently consists of approximately 50 scientists, engineers, technicians and machinists....                                     \n",
       "20   Financial transactional data. Experience with consumer/consumer-facing data. Utilize Jupyter Notebook to create, test, and display data cleaning, data science...    \n",
       "21   By creating your profile on SymbaSync you will be eligible for this job opportunity, and all others being hired for on the site. Our client is looking for an...     \n",
       "22   2+ years’ experience as a Data Analyst or Business Data Analyst. Implement new data analysis methodologies. Develop and implement data analyses, data collection...  \n",
       "23   Universal Music Group is looking for a Data Scientist to join our in-house Data Science R&D team, working across prediction, segmentation, price optimization,...    \n",
       "24   Our Data team is seeking an Associate Data Scientist to help us ensure we deliver the highest quality Global Places product on the market....                        \n",
       "25   We are looking for data scientists who are passionate about using data to drive strategy and product recommendations....                                             \n",
       "26   Use SAS to apply the IRS sampling methodology set forth in IRM 42(18) at a global tax firm. Compensation DOE. Job Type: Full-time Salary: $75,000.00 to $150...      \n",
       "27   We are looking for a Data Scientist interested in solving one of the world's largest problems:. Leverage a unique, diverse, and deep data set to find...             \n",
       "28   CannaData Solutions is looking to add a Data Scientist with a diverse toolkit to their development team. Ability to explain data analysis to a non-technical...      \n",
       "29   Conduct data analysis on Identity data within SPE. IT Business Data Analysis Intern, Corporate – Summer 2018. The IT Business Data Analyst Intern will join the...   \n",
       "30   Skilled scientists and thinkers. Support Integrated Product Teams throughout the product life cycle, integrating data across tools and providing analyses from...    \n",
       "..                                                                                                                                                                 ...    \n",
       "547  Information management and document distribution in virtual data rooms, like Microsoft SharePoint. Secondary research for financial and statistical data on...       \n",
       "548  P UR P O S E OF JO B : Pe rf o r ms D ocu m ent C on tr o l and Rec o r d C o n t r ol a c t i v i ti e s , and p r o v i des ad m i n i s t r a ti v e s uppo...    \n",
       "549  1-2 years Data Entry Experience. Insight Global is looking for a Data Entry Clerk to sit onsite at one of our clients in Palo Alto, Ca....                           \n",
       "550  Candidate will be responsible for business requirements gathering, data flow diagramming, presentations, and develop training manuals and training videos....        \n",
       "551  Excel data manipulation. Data visualization and reporting. Strong analytical and data skills. You are data driven and analytical....                                 \n",
       "552  Strong SQL, comfortable writing queries, data processing scripts, and understanding RDBMS data structures. Able to visualize data effectively....                    \n",
       "553  Develop rich, interactive, visually striking graphics and data visualizations of large amounts of data. Data manipulation and transformation skills....              \n",
       "554  Job Description Hi, We are currently Looking for 8 Junior Informatica Data Analysts Location : Fremont, CA (Preferred Local to Bay Area) Skills Required 1...        \n",
       "555  Analyze data processes in documentation. Use system reports and analyses to identify potentially problematic data, make corrections, and determine root cause...     \n",
       "556  Knowledge in data manipulation and analysis (R/SAS/Stata, SQL/Hive). Knowledge in quantitative research methodologies (e.g., survey sampling and design,...          \n",
       "557  Lead the implementation of data standards and common data elements for data collection. Create data dictionaries and libraries that document how data are housed...  \n",
       "558  The Data Center Site Engineering team is looking for an intern to work at the intersection of the data center and the hardware that fills it....                     \n",
       "559  Experience with analytical tools supporting data evaluation and reporting, as well as querying large, complex data sets (Splunk, Tableau, SQL, R, etc)....           \n",
       "560  Hadoop, Teradata, MPP, Database programming, Understanding of data models.  Collaborate with developers and business users for overall design oversight on Big...   \n",
       "561  We are seeking a PBM Business Analyst in the Washington, DC area. Can work remotely with some travel once every 6 to 8 weeks to Hartford, CT or Richmond, VA...      \n",
       "562  Technologist - Data Analysis-92954. Act as a solutions engineer working within modern architectures and frameworks while experimenting with newer technologies...    \n",
       "563  Perform routine data investigations to profile and analyze data sets to address data quality and integrity. Principal Data Analyst-92956....                         \n",
       "564  This Product Manager will be responsible for product development related to data collection, aggregation, derived data products and all related operations...        \n",
       "565  Highly proficient with data analytics, and experience in data manipulation using a variety of tools. Natural curiosity, and a demonstrated ability to turn...        \n",
       "566  Running specified queries using Burning Glass’s proprietary labor market database and other published data sources, preparing data for presentation, and...          \n",
       "567  Organize and structure performance related data from a variety of sources (paid media, social platforms, web analytics solutions, 3rd party data providers)....      \n",
       "568  Data visualization experience. Knowledge of data analysis, statistics, mathematical modeling, and/or machine learning....                                            \n",
       "569  Be able to write emails properly -- we communicate with global leaders, innovators, investors, entrepreneurs, C-level executives and folks within the IoT...         \n",
       "570   jQuery or other javascript framework within data collection system Write specialized macros to extract/ format data....                                           \n",
       "571  You will have the chance to write highly optimised code to advance our internal Data Science toolbox, and you'll develop world-class data science products for...    \n",
       "572  Compiles data from various sources, verifies data. Ability to maintain confidentiality and handle sensitive data....                                                 \n",
       "573  Amazon is seeking a French Language Data Associate to join our Kindle data team. The French Language Data Associate must have a passion for data, efficiency,...     \n",
       "574  Patient data) to identify trends. Data munging and mining is a thing you’ve done. Ability to story tell and visualize data coherently (d3, ggplot2, etc.)....        \n",
       "575  Conduct data exploration, solve data problems, and execute algorithmic data processing using SQL. Provide specifications to Data Warehouse team for...               \n",
       "576  Support data migration projects, conversion, and product upgrades. Will work closely with development and infrastructure staff to maintain secure access to data...  \n",
       "\n",
       "[576 rows x 5 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the library\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import urllib, requests, re, pandas as pd\n",
    "\n",
    "# indeed.com url\n",
    "base_url = 'http://www.indeed.com/jobs?q=data+scientist&jt=fulltime&sort='\n",
    "sort_by = 'date'          # sort by data\n",
    "start_from = '&start='    # start page number\n",
    "\n",
    "pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "df = pd.DataFrame()   # create a new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for page in range(1,10): # page from 1 to 100 (last page we can scrape is 100)\n",
    "    page = (page-1) * 10  \n",
    "    url = \"%s%s%s%d\" % (base_url, sort_by, start_from, page) # get full url \n",
    "    target = Soup(urllib.request.urlopen(url), \"lxml\") \n",
    "            \n",
    "    targetElements = target.findAll('div', attrs={'class' : '  row  result'}) # we're interested in each row (= each job)\n",
    "    \n",
    "    # trying to get each specific job information (such as company name, job title, urls, ...)\n",
    "    for elem in targetElements: \n",
    "        comp_name = elem.find('span', attrs={'itemprop':'name'}).getText().strip()\n",
    "        job_title = elem.find('a', attrs={'class':'turnstileLink'}).attrs['title']\n",
    "        home_url = \"http://www.indeed.com\"\n",
    "        job_link = \"%s%s\" % (home_url,elem.find('a').get('href'))\n",
    "        job_addr = elem.find('span', attrs={'itemprop':'addressLocality'}).getText()\n",
    "        job_posted = elem.find('span', attrs={'class': 'date'}).getText()\n",
    "\n",
    "        comp_link_overall = elem.find('span', attrs={'itemprop':'name'}).find('a')\n",
    "        if comp_link_overall != None: # if company link exists, access it. Otherwise, skip.\n",
    "            comp_link_overall = \"%s%s\" % (home_url, comp_link_overall.attrs['href'])\n",
    "        else: comp_link_overall = None\n",
    "\n",
    "    # add a job info to our data frame\n",
    "        df = df.append({'comp_name': comp_name, 'job_title': job_title, \n",
    "                        'job_link': job_link, 'job_posted': job_posted,\n",
    "                        'overall_link': comp_link_overall, 'job_location': job_addr,\n",
    "                        'overall_rating': None, 'wl_bal_rating': None, \n",
    "                        'benefit_rating': None, 'jsecurity_rating': None, \n",
    "                        'mgmt_rating': None, 'culture_rating': None\n",
    "                       }, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://www.indeed.com/jobs?q=data+scientist&l=boston&sort='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.indeed.com/jobs?q=data+scientist&jt=fulltime&sort=date&start=0'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just posted\n",
      "Just posted\n",
      "Just posted\n",
      "Just posted\n",
      "Just posted\n",
      "Just posted\n",
      "Just posted\n",
      "Just posted\n",
      "Today\n",
      "Today\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-bc9b5ce0b9b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mhome_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www.indeed.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mjob_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhome_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mjob_posted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_posted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "for page in range(1): # page 1 \n",
    "    url = \"%s%s%s%d\" % (base_url, sort_by, start_from, page) # get full url\n",
    "    targetElements = target.findAll(name='div', attrs={'class':'row'})\n",
    "    for elem in targetElements: \n",
    "        job_title = elem.find(name = 'a', attrs={'data-tn-element':'jobTitle'}).attrs['title']\n",
    "        company_name = elem.find(name='span', attrs={'class':'company'}).text.strip()\n",
    "        home_url = \"http://www.indeed.com\"\n",
    "        job_link = \"%s%s\" % (home_url,elem.find('a').get('href'))\n",
    "        job_posted = elem.find('span', attrs={'class': 'date'}).text.strip()\n",
    "        print(job_posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = crawls.iloc[0]\n",
    "description = row['description']\n",
    "location = row['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"https://www.indeed.com/jobs?q={description}&l={location}\"\n",
    "url = t.format(description=description, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_set = crawls['location'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new york',\n",
       " 'los angeles',\n",
       " 'chicago',\n",
       " 'san francisco',\n",
       " 'san jose',\n",
       " 'palo alto',\n",
       " 'boston']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_set = crawls['description'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'data', 'machine learning', 'optimization', 'deep learning']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "company = []\n",
    "location = []\n",
    "jd = []\n",
    "url = \"https://www.indeed.com/m/jobs?q=data+science&l=boston&sort=date\"\n",
    "job_url = []\n",
    "for i in range(1):\n",
    "    \n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    all_matches = soup.findAll(attrs={'rel':['nofollow']})\n",
    "    for each in all_matches:\n",
    "        jd_url= 'http://www.indeed.com/m/'+each['href']\n",
    "        jd_page =urlopen(jd_url)\n",
    "        jd_soup = BeautifulSoup(jd_page, 'html.parser')\n",
    "        jd_desc = jd_soup.findAll(attrs={'id':['desc']})\n",
    "        title.append(jd_soup.body.p.b.font.text)\n",
    "        company.append(jd_desc[0].span.text)\n",
    "        location.append(jd_soup.body.p.span.text)\n",
    "        jd.append(jd_desc[0].text)\n",
    "        job_url.append(jd_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = {'title': title,\n",
    "         'company': company,\n",
    "         'location': location,\n",
    "         'jd': jd,\n",
    "         'job_url': job_url}\n",
    "df = pd.DataFrame.from_dict(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>jd</th>\n",
       "      <th>job_url</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Alexa Skills Kit is seeking an experienced and highly motivated Data Associate to join our Alexa Data Team.\\n\\nThis role focuses on US English language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with mi...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=69cd0278280af092</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Data Associate - US English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Summer 2018Summer Associate (INTERN): CSAIL ALLIANCES: Marketing, Business Development, data managementFor summer 2018 we are seeking a full time Summer Intern to join the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in the CSAIL Alliances department. CSAIL is the largest lab at MIT with over 1000 people, 60 research groups and 900+ active projects. The work at the lab spans artificial intelligence, robotics, cryptography, natural language processing, networks, languag...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=178b26e1f55f4fcd</td>\n",
       "      <td>Cambridge, MA 02142</td>\n",
       "      <td>Summer Associate; Marketing, Business Development, Data Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DataXu</td>\n",
       "      <td>dataxu® helps marketing professionals use data to improve their advertising. Our software empowers our customers to connect with real people across all channels, including TV, capturing consumers’ attention when and where it matters most. We’re pumped about the recognition our software has earned—such as being named a Leader in The Forrester Wave™: Omnichannel Demand-Side Platforms, Q2 2017 and receiving the top usability score among competitors in a head-to-head study by Validately—but we’r...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=08a5a6c398a9f35a</td>\n",
       "      <td>Boston, MA 02210</td>\n",
       "      <td>Data Science Intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commonwealth of Massachusetts</td>\n",
       "      <td>The Executive Office of Labor and Workforce Development (EOLWD) is responsible for five agencies and departments under the organization. EOLWD and its agencies are committed to developing a world-class, highly skilled labor force to support business growth and innovation in the Commonwealth.\\n\\nRESPONSIBILITIES\\nStrategy &amp; Planning\\n\\nCreate short-term tactical solutions to achieve long-term objectives and an overall data management roadmap\\nAssist with assessing and determining governance, ...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=bb857e181493a30e</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>ODI Data Warehouse Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Amazon Devices is seeking an experienced and highly motivated Data Associate to join our team.\\n\\nThis role focuses on Spanish language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with minimal direction\\...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=3ddf01d6c6afafea</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Data Associate - Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         company  \\\n",
       "0                     Amazon.com   \n",
       "1                    4 hours ago   \n",
       "2                         DataXu   \n",
       "3  Commonwealth of Massachusetts   \n",
       "4                     Amazon.com   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    jd  \\\n",
       "0  Alexa Skills Kit is seeking an experienced and highly motivated Data Associate to join our Alexa Data Team.\\n\\nThis role focuses on US English language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with mi...   \n",
       "1  Summer 2018Summer Associate (INTERN): CSAIL ALLIANCES: Marketing, Business Development, data managementFor summer 2018 we are seeking a full time Summer Intern to join the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in the CSAIL Alliances department. CSAIL is the largest lab at MIT with over 1000 people, 60 research groups and 900+ active projects. The work at the lab spans artificial intelligence, robotics, cryptography, natural language processing, networks, languag...   \n",
       "2  dataxu® helps marketing professionals use data to improve their advertising. Our software empowers our customers to connect with real people across all channels, including TV, capturing consumers’ attention when and where it matters most. We’re pumped about the recognition our software has earned—such as being named a Leader in The Forrester Wave™: Omnichannel Demand-Side Platforms, Q2 2017 and receiving the top usability score among competitors in a head-to-head study by Validately—but we’r...   \n",
       "3  The Executive Office of Labor and Workforce Development (EOLWD) is responsible for five agencies and departments under the organization. EOLWD and its agencies are committed to developing a world-class, highly skilled labor force to support business growth and innovation in the Commonwealth.\\n\\nRESPONSIBILITIES\\nStrategy & Planning\\n\\nCreate short-term tactical solutions to achieve long-term objectives and an overall data management roadmap\\nAssist with assessing and determining governance, ...   \n",
       "4  Amazon Devices is seeking an experienced and highly motivated Data Associate to join our team.\\n\\nThis role focuses on Spanish language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with minimal direction\\...   \n",
       "\n",
       "                                               job_url             location  \\\n",
       "0  http://www.indeed.com/m/viewjob?jk=69cd0278280af092           Boston, MA   \n",
       "1  http://www.indeed.com/m/viewjob?jk=178b26e1f55f4fcd  Cambridge, MA 02142   \n",
       "2  http://www.indeed.com/m/viewjob?jk=08a5a6c398a9f35a     Boston, MA 02210   \n",
       "3  http://www.indeed.com/m/viewjob?jk=bb857e181493a30e           Boston, MA   \n",
       "4  http://www.indeed.com/m/viewjob?jk=3ddf01d6c6afafea           Boston, MA   \n",
       "\n",
       "                                                                title  \n",
       "0                                         Data Associate - US English  \n",
       "1  Summer Associate; Marketing, Business Development, Data Management  \n",
       "2                                                 Data Science Intern  \n",
       "3                                    ODI Data Warehouse Administrator  \n",
       "4                                            Data Associate - Spanish  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(url):\n",
    "    url_id = url.split('=')[1]\n",
    "    return url_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['job_url'].apply(extract_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>jd</th>\n",
       "      <th>job_url</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69cd0278280af092</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Alexa Skills Kit is seeking an experienced and highly motivated Data Associate to join our Alexa Data Team.\\n\\nThis role focuses on US English language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with mi...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=69cd0278280af092</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Data Associate - US English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178b26e1f55f4fcd</th>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Summer 2018Summer Associate (INTERN): CSAIL ALLIANCES: Marketing, Business Development, data managementFor summer 2018 we are seeking a full time Summer Intern to join the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in the CSAIL Alliances department. CSAIL is the largest lab at MIT with over 1000 people, 60 research groups and 900+ active projects. The work at the lab spans artificial intelligence, robotics, cryptography, natural language processing, networks, languag...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=178b26e1f55f4fcd</td>\n",
       "      <td>Cambridge, MA 02142</td>\n",
       "      <td>Summer Associate; Marketing, Business Development, Data Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08a5a6c398a9f35a</th>\n",
       "      <td>DataXu</td>\n",
       "      <td>dataxu® helps marketing professionals use data to improve their advertising. Our software empowers our customers to connect with real people across all channels, including TV, capturing consumers’ attention when and where it matters most. We’re pumped about the recognition our software has earned—such as being named a Leader in The Forrester Wave™: Omnichannel Demand-Side Platforms, Q2 2017 and receiving the top usability score among competitors in a head-to-head study by Validately—but we’r...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=08a5a6c398a9f35a</td>\n",
       "      <td>Boston, MA 02210</td>\n",
       "      <td>Data Science Intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb857e181493a30e</th>\n",
       "      <td>Commonwealth of Massachusetts</td>\n",
       "      <td>The Executive Office of Labor and Workforce Development (EOLWD) is responsible for five agencies and departments under the organization. EOLWD and its agencies are committed to developing a world-class, highly skilled labor force to support business growth and innovation in the Commonwealth.\\n\\nRESPONSIBILITIES\\nStrategy &amp; Planning\\n\\nCreate short-term tactical solutions to achieve long-term objectives and an overall data management roadmap\\nAssist with assessing and determining governance, ...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=bb857e181493a30e</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>ODI Data Warehouse Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ddf01d6c6afafea</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Amazon Devices is seeking an experienced and highly motivated Data Associate to join our team.\\n\\nThis role focuses on Spanish language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with minimal direction\\...</td>\n",
       "      <td>http://www.indeed.com/m/viewjob?jk=3ddf01d6c6afafea</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Data Associate - Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company  \\\n",
       "id                                                \n",
       "69cd0278280af092                     Amazon.com   \n",
       "178b26e1f55f4fcd                    4 hours ago   \n",
       "08a5a6c398a9f35a                         DataXu   \n",
       "bb857e181493a30e  Commonwealth of Massachusetts   \n",
       "3ddf01d6c6afafea                     Amazon.com   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   jd  \\\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "69cd0278280af092  Alexa Skills Kit is seeking an experienced and highly motivated Data Associate to join our Alexa Data Team.\\n\\nThis role focuses on US English language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with mi...   \n",
       "178b26e1f55f4fcd  Summer 2018Summer Associate (INTERN): CSAIL ALLIANCES: Marketing, Business Development, data managementFor summer 2018 we are seeking a full time Summer Intern to join the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in the CSAIL Alliances department. CSAIL is the largest lab at MIT with over 1000 people, 60 research groups and 900+ active projects. The work at the lab spans artificial intelligence, robotics, cryptography, natural language processing, networks, languag...   \n",
       "08a5a6c398a9f35a  dataxu® helps marketing professionals use data to improve their advertising. Our software empowers our customers to connect with real people across all channels, including TV, capturing consumers’ attention when and where it matters most. We’re pumped about the recognition our software has earned—such as being named a Leader in The Forrester Wave™: Omnichannel Demand-Side Platforms, Q2 2017 and receiving the top usability score among competitors in a head-to-head study by Validately—but we’r...   \n",
       "bb857e181493a30e  The Executive Office of Labor and Workforce Development (EOLWD) is responsible for five agencies and departments under the organization. EOLWD and its agencies are committed to developing a world-class, highly skilled labor force to support business growth and innovation in the Commonwealth.\\n\\nRESPONSIBILITIES\\nStrategy & Planning\\n\\nCreate short-term tactical solutions to achieve long-term objectives and an overall data management roadmap\\nAssist with assessing and determining governance, ...   \n",
       "3ddf01d6c6afafea  Amazon Devices is seeking an experienced and highly motivated Data Associate to join our team.\\n\\nThis role focuses on Spanish language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with minimal direction\\...   \n",
       "\n",
       "                                                              job_url  \\\n",
       "id                                                                      \n",
       "69cd0278280af092  http://www.indeed.com/m/viewjob?jk=69cd0278280af092   \n",
       "178b26e1f55f4fcd  http://www.indeed.com/m/viewjob?jk=178b26e1f55f4fcd   \n",
       "08a5a6c398a9f35a  http://www.indeed.com/m/viewjob?jk=08a5a6c398a9f35a   \n",
       "bb857e181493a30e  http://www.indeed.com/m/viewjob?jk=bb857e181493a30e   \n",
       "3ddf01d6c6afafea  http://www.indeed.com/m/viewjob?jk=3ddf01d6c6afafea   \n",
       "\n",
       "                             location  \\\n",
       "id                                      \n",
       "69cd0278280af092           Boston, MA   \n",
       "178b26e1f55f4fcd  Cambridge, MA 02142   \n",
       "08a5a6c398a9f35a     Boston, MA 02210   \n",
       "bb857e181493a30e           Boston, MA   \n",
       "3ddf01d6c6afafea           Boston, MA   \n",
       "\n",
       "                                                                               title  \n",
       "id                                                                                    \n",
       "69cd0278280af092                                         Data Associate - US English  \n",
       "178b26e1f55f4fcd  Summer Associate; Marketing, Business Development, Data Management  \n",
       "08a5a6c398a9f35a                                                 Data Science Intern  \n",
       "bb857e181493a30e                                    ODI Data Warehouse Administrator  \n",
       "3ddf01d6c6afafea                                            Data Associate - Spanish  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'08a5a6c398a9f35a': {'company': 'DataXu',\n",
       "  'jd': 'dataxu® helps marketing professionals use data to improve their advertising. Our software empowers our customers to connect with real people across all channels, including TV, capturing consumers’ attention when and where it matters most. We’re pumped about the recognition our software has earned—such as being named a Leader in The Forrester Wave™: Omnichannel Demand-Side Platforms, Q2 2017 and receiving the top usability score among competitors in a head-to-head study by Validately—but we’re even more excited about the success our customers achieve by leveraging our technology. With 12 offices around the world, we’re here to help power our customers’ business forward.\\n\\ndataxu’s Optimization Group develops algorithms to improve dataxu’s media buying platform. Our problems are exciting and challenging as they involve the analysis of big data for optimal bidding in a real-time system. The successful candidate will help improve both our algorithms and infrastructure and will have a chance to see their work impact dataxu’s system.\\n\\nAbout You\\n\\n\\nStudying for a PhD or Masters Degree in Machine Learning, Operations Research, Applied Math, or similar field.\\nOutstanding undergraduates with relevant experience will also be considered.\\nExperience with analysis tools such as Spark, Python, R, Matlab, Weka, or similar.\\nExcellent understanding of algorithms and data structures for optimization\\nExperience with UNIX environments (Linux)\\nStrong problem solving and analytical skills\\nExperience with software development in Java or Python\\n\\nBonus Points\\n\\n\\nExperience with TB size datasets\\n\\nKnowledge of markets, auctions and/or advertising\\nExperience with Deep Learning\\n\\nDay-to-Day at the ‘xu\\n\\nWe’re obsessed with our customers, our product, our people and innovation—all of which tie right in with our corporate values. We Collaborate across all teams and global offices. Our customers Trust us because we put transparency and their needs first. Innovation is part of everything that we do. Excellence is our standard mode of operation. And of course, Customer Obsession. We wouldn’t be here without our customers! So, interested in working here yet? Visit dataxu.com to learn more!\\n\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\nDataXu - \\n1 hour ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=08a5a6c398a9f35a',\n",
       "  'location': 'Boston, MA 02210',\n",
       "  'title': 'Data Science Intern'},\n",
       " '178b26e1f55f4fcd': {'company': '4 hours ago',\n",
       "  'jd': 'Summer 2018Summer Associate (INTERN): CSAIL ALLIANCES: Marketing, Business Development, data managementFor summer 2018 we are seeking a full time Summer Intern to join the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in the CSAIL Alliances department. CSAIL is the largest lab at MIT with over 1000 people, 60 research groups and 900+ active projects. The work at the lab spans artificial intelligence, robotics, cryptography, natural language processing, networks, languages, machine learning, computer vision and more.CSAIL Alliances is responsible for creating and maintaining productive relationships in all research areas with industry, organizations and governmental entities . Alliances is a global program that includes the CSAIL Alliance Program (CAP), the FinTech@CSAIL research initiative, the Cybersecurity@CSAIL research initiative, SystemsThatLearn@CSAIL (AI) research initiative, recruiting activity, professional development programs and the Industry Visiting Researcher program.This is a paid temporary summer position (30-40 hours per week) located on the MIT campus in Cambridge, MA. Anticipated timeframe for the assignment is from May 29-August 10 2018.The Summer Intern will work with marketing, client relations, data management, professional education offerings and program development. Specific duties may include:Updating salesforce database and running reportsProducing business use cases on technology adoptionManaging elements of Social media campaignsResearching status reports across all areas of the labUpdating search tools for research, patents, projects and open source technologyEvent management assistanceCreating research summaries on the latest work of world renowned researchers such as Mike Stonebreaker, Ron Rivest and Tim Berners LeeOther projects as needed.The Summer Intern will have the opportunity to gain valuable experience, work with top researchers and connect with technology leaders from a variety of companies and industries.No experience necessary. Open to Rising college sophomore or Rising junior with degree in process. Marketing, Business, English, or Management information systems major with a love of technology, positive attitude and solid team player required. Excellent writing and communications skills. Familiarity with databases a plus.Job Types: Full-time, Temporary, Internship\\n4 hours ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=178b26e1f55f4fcd',\n",
       "  'location': 'Cambridge, MA 02142',\n",
       "  'title': 'Summer Associate; Marketing, Business Development, Data Management'},\n",
       " '18e3283a20654629': {'company': 'State Street',\n",
       "  'jd': 'GM Funding and Collateral Transformation (“FaCT”) is seeking a Business Analyst, AVP, to support product development and strategy. The successful candidate will exhibit a good understanding of financial products and will interface with an array of business support partners including trading, legal, compliance, operations, accounting, risk, and project management. The individual will be equally at ease discussing business and technical issues, and will be able to lead solution discovery.\\n\\nResponsibilities:\\nDirects efforts cross-functionally and uses good understanding of business systems, financial industry, and product development to support projects through their life cycle, with emphasis on the analysis stage\\nDemonstrates an understanding of the potential organizational impact of various challenges and proposed solutions and an ability to facilitate collaboration to achieve resolution\\nIdentifies, compiles, analyzes and documents requirements that accurately and thoroughly reflect business needs\\nMonitors project planning and management by documenting and maintaining plans and managing issue logs\\nContributes to the creation and completion of presentations for senior management and other internal and external stakeholders\\nActs in accordance with Risk Excellence and role models Ethical behavior and decision making as part of our Way Ahead foundation\\n\\nJob Requirements:\\nBachelor’s degree in finance, economics or related field, MBA preferred\\n5-7 years relevant experience in financial service industry with an emphasis on investment and collateral management\\nStrong knowledge of fixed income, equities and derivatives\\nProficient knowledge of Microsoft’s Excel, Word and PowerPoint\\nAbility to work both independently and as a part of a team\\nExperience working under tight deadlines with multiple deliverables\\nExcellent verbal and written communication and presentation skills\\nState Street - \\n3 hours ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=18e3283a20654629',\n",
       "  'location': 'Boston, MA',\n",
       "  'title': 'Business Analyst'},\n",
       " '2a43845f76f9552a': {'company': '3 hours ago',\n",
       "  'jd': 'Do you worry your next job will bring only a paycheck? Good for you!Since 1995, NTI, (www.nticentral.org), has provided employment services such as skills training, job placement, and reimbursements for work-related expenses to Americans with disabilities, giving them the resources to succeed in the workplace and a path to economic independence. Our clients tell us what a difference our efforts make every day—and it is this difference that drives ever action and decision behind our mission!As a non-profit that’s growing rapidly, we’re looking for empathetic, motivated, and enthusiastic people to join us. We’d love to hear why you’re the right person to join our organization.Position Summary: The Contact Center and Recruiting Services Administrator will be responsible for supporting the departments by responding to incoming emails, maintaining the Knowledgebase, generating reports and drafting mass emails and newsletters. Other responsibilities include monitoring recruiter interviews and documentation to ensure accuracy, consistency, and compliance with policy, procedures, and service quality standards. In addition, this position is key in identifying issues and patterns which might be indicative of larger problems and may need to be escalated to a Manager.Essential Duties and Responsibilities: Respond to emails sent to internal email boxesAccurately document correspondence within the Talent Management System and complete any required follow-up workGenerate and graph weekly reports regarding call center and recruiting metricsAssist with finding and developing content to create weekly newslettersParticipates in regular training and meeting activities to ensure ongoing awareness of changes in procedures, positions and services at NTIExhibits a strong customer service focus with the ability to resolve routine customer complaints during the Applicant’s first contactComplete weekly quality assurance audits of JSS Interviews and Taleo codingMonitor and score recruiter interviews in accordance with policy, procedures and service quality standardsMaintains knowledge of positions, recruiting plans, procedures and services offered by NTIMentor RecruitersOther duties may be assigned to meet business needsMinimum Requirements: High School Diploma or Equivalent1+ years administrative experience, strong computer experience and customer service experienceExcellent verbal/written/interpersonal communication skills; must read, write, speak and hear EnglishSolid time management skillsGood listening and problem solving skillsAbility to be a team player to meet goals and objectives established by the organizationBasic math skillsStrong attention to detailDemonstrated ability to use Microsoft Excel including but not limited to knowledge of using formulas, sorting and graphing data.Ability to type at least 45 wpmAbility to thrive in a fast-paced environmentSensitivity to work with individuals with disabilitiesAbility to pass two background checks, one with the Social Security Administration which includes fingerprints * Cover letter must be submitted with applicationPLEASE USE THIS TO APPLY: https://chm.tbe.taleo.net/chm03/ats/careers/v2/viewRequisition?org=NTI&cws;=47&rid;=349Preferred Requirements: Previous quality assurance experiencePrevious experience working for NTISpecial Position Requirements: May require some weekend hours to accommodate job duties.Minimum Computer Requirements:   * 1.6 GHz Processor speed or higher * 8 GB RAM of Memory * 20 GB of free hard drive space * Monitor with 1024 x 768 resolution or higher * Standard Keyboard & MouseSoftware Requirements:   * Windows 7, 8.1 or 10 * Microsoft Internet Explorer version 10 or 11, or Google Chrome or Mozilla Firefox 10.0+ * Microsoft Office Word, Excel and PowerPoint * Microsoft Outlook (not required but good to have) * Active and an updated Antivirus Software * Adobe Acrobat viewer * Current version of JAVA * NTI provides remote support through NSK (NTI may request this software to be installed when support is needed) * Sorry, no Apple/Macs Internet Connection: DSL, Cable, or FiOS high speed connection with at least 3 mbps download speed and 1 mbps upload speed required * No Satellite or dialup access is also not acceptedOther Requirements: Corded USB headset with micPrinterHome Office Setup: Office set up in a quiet and safe space in the homeWhy work with NTI:  We offer a casual yet professional work environment with EXCELLENT benefits for full-time employees, including a very generous employer contribution to your health and dental benefits, a medical flexible spending account (FSA) with employer contribution, a 403b plan with 5 percent employer contribution of gross salary after one year of employment (no employee contribution required), and 100% employer-paid LTD, STD, AD&D;, and life insurances. We provide generous paid time-off, including 12 paid company holidays, vacation, sick and floating holiday time, and half-day Friday’s in the summer months of July and August. We also offer tuition reimbursement if you have future plans to continue your studies.Americans with Disability Specifications Physical Demands: While performing the duties of this job, the employee is required to stand; or sit; use hands to finger, handle, or feel objects, and type on a keyboard; reach with hands and arms; balance; speak clearly and hear; Specific vision abilities required by the job include close vision depth perception, and the ability to adjust focus.Work Environment: Work environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.While performing the duties of this job, the employee is working from the quiet of their home office. No background noise such as TV, dogs barking, cell phone ringing, people talking, etcReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this job. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or protected veteran status.EOE Disability/VetsPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.Updated June 2017Job Type: Full-timeSalary: $15.00 to $16.00 /hour\\n3 hours ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=2a43845f76f9552a',\n",
       "  'location': 'Boston, MA 02116',\n",
       "  'title': 'Call Center Services & Recruiting Administrator'},\n",
       " '3ddf01d6c6afafea': {'company': 'Amazon.com',\n",
       "  'jd': 'Amazon Devices is seeking an experienced and highly motivated Data Associate to join our team.\\n\\nThis role focuses on Spanish language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with minimal direction\\nHandling unique data analysis requests from a range of data customers\\nContributing to process improvements to reduce handling time and improve output\\nIn addition, the Data Associate will need to quickly understand changes to conventions deployed in response to customers’ requests and change workflows accordingly. The Associate should be able to contribute to improvements in the software tools by identifying bugs and suggesting enhancements.\\n\\nThe Data Associate must have a passion for data, efficiency, and accuracy. The ideal candidate also:\\n\\nShows proactive behavior in addressing issues and problems\\nPossesses excellent communication and organizational skills, and is very detailed-oriented\\nIs comfortable working in a fast paced, highly collaborative, dynamic work environment\\nDemonstrates willingness to support several projects at one time, and to accept re-prioritization as necessary\\nAdapts quickly to keep up with changing project conventions and new projects\\n\\nBasic Qualifications\\n\\nNative-like fluency in spoken and written Spanish language varieties\\nExperience using English in a professional setting\\nAble to work with audio content (wearing headsets) for a portion of the day\\nWorking knowledge of computers\\n\\nPreferred Qualifications\\n\\nBachelor’s degree in a relevant field; a degree working with language, linguistics preferred\\nExperience working as a transcriber or annotator\\nPractical knowledge of data processing needs and trade-offs\\nOne or more years experience working with language data, including experience with annotation and other forms of data markup Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\\nAmazon.com - \\n56 minutes ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=3ddf01d6c6afafea',\n",
       "  'location': 'Boston, MA',\n",
       "  'title': 'Data Associate - Spanish'},\n",
       " '4080faa10ee59ef3': {'company': 'McKinsey & Company',\n",
       "  'jd': \"Qualifications\\n\\nMBA or advanced degree in Operations Research, Computer Science, Engineering, Applied Math, Quantitative social sciences or related field\\n5+ years of experience in front line and/or field analytical and methodological services in the telecom, utilities, travel/transport, or industrial equipment industries\\nDeep technical knowledge in predictive analytics, machine learning, optimization, and fluent in a number of the following technologies: R, Python, SAS, Tableau, IBM, Alteryx, Anaplan\\nStrong intrinsic problem-solving skills, ability to structure and solve problems and conduct and interpret analysis independently, with demonstrated analytic and quantitative skills\\nSkills to communicate complex ideas effectively\\nWillingness to travel up to 80%\\n\\nWho You'll Work With\\n\\nYou’ll be working with McKinsey’s Operations practice in one of our North American offices. Our Operations practice assists our clients in solving complex operational challenges. Blending strategic thinking with hands-on practicality, our teams of consultants and experts work to develop and implement operational strategies that solve our clients' most critical problems.\\nService Operations is a growing service line with deep functional expertise implementing holistic transformation including Customer Experience/Service Design, Frontline & Field Operations, Service Factory Operations, Corporate Business Functions, and Customer Care with cross-cutting foundation capabilities (e.g., Lean expertise; IT enablement; Performance transformation) to deliver significant and sustainable cost impact.\\n\\nWhat You'll Do\\n\\nAs an Analytics Expert, you will shape the way global customer service organizations operate, by solving inefficiencies in workforce productivity, fleet maintenance, and customer experience.\\nYou will create valuable, transformative business strategies through the measurement, manipulation and reporting of broad sets of data. You will apply state-of-the-art workforce analytics and optimization tools and techniques to: understand ideal shift patterns and lengths to accommodate changes in clients’ field service strategy, determine optimal contact center headcount to meet clients’ SLA, labor cost, and customer experience objectives, optimize size and mix of delivery fleet to improve service while reducing costs and meeting forecasted demand, calculate optimal overtime usage in a factory setting while balancing full-time, part-time, and temp employee levels, as well as analyze field service efficiency and design optimal work order queues and plans to minimize travel time.\\nMcKinsey & Company - \\n1 hour ago\",\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=4080faa10ee59ef3',\n",
       "  'location': 'Boston, MA',\n",
       "  'title': 'Workforce Analytics Consultant'},\n",
       " '69cd0278280af092': {'company': 'Amazon.com',\n",
       "  'jd': 'Alexa Skills Kit is seeking an experienced and highly motivated Data Associate to join our Alexa Data Team.\\n\\nThis role focuses on US English language data, primarily in the areas of transcription, text annotation, and general data analysis deliverables. The Associate must be capable of:\\n\\nTranscribing and annotating high priority deliverables\\nDelivering high quality work under aggressive deadlines\\nTranslating established guidelines into daily work practices\\nWorking autonomously with minimal direction\\nHandling unique data analysis requests from a range of data customers\\nContributing to process improvements to reduce handling time and improve output\\nIn addition, the Data Associate will need to quickly understand changes to conventions deployed in response to customers’ requests and change workflows accordingly. The Associate should be able to contribute to improvements in the software tools by identifying bugs and suggesting enhancements.\\n\\nThe Data Associate must have a passion for data, efficiency, and accuracy. The ideal candidate also:\\n\\nShows proactive behavior in addressing issues and problems\\nPossesses excellent communication and organizational skills, and is very detailed-oriented\\nIs comfortable working in a fast paced, highly collaborative, dynamic work environment\\nDemonstrates willingness to support several projects at one time, and to accept re-prioritization as necessary\\nAdapts quickly to keep up with changing project conventions and new projects\\n\\nBasic Qualifications\\n\\nNative-like fluency in spoken and written US English language varieties\\nExperience using English in a professional setting\\nAble to work with audio content (wearing headsets) for a portion of the day\\nWorking knowledge of computers\\n\\nPreferred Qualifications\\n\\nBachelor’s degree in a relevant field; a degree working with language, linguistics preferred\\nExperience working as a transcriber or annotator\\nPractical knowledge of data processing needs and trade-offs\\nOne or more years experience working with language data, including experience with annotation and other forms of data markup\\nAmazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\\nAmazon.com - \\n56 minutes ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=69cd0278280af092',\n",
       "  'location': 'Boston, MA',\n",
       "  'title': 'Data Associate - US English'},\n",
       " '6d68aeaccd78f455': {'company': 'Partners HealthCare',\n",
       "  'jd': 'The MGPO Physician Analytics\\n& Business Intelligence team within the MGPO Finance division is perceived\\nas one of the more advanced and robust analytic groups within the Partners\\nHealthcare umbrella. This team is responsible for managing the platform known\\nas IPORT (Interactive Performance Optimization Reporting Tool) which combines\\nadministrative, financial and clinical data sets in a data warehouse and\\nprovides the ability to view drivers in volume and reimbursement trends tied to\\nthe revenue cycle through comprehensive reports, scorecard capabilities,\\ninteractive dashboards and ad hoc OLAP reporting tools.\\n\\nAs a Data Warehouse Analyst\\nII, you will be part of a team of highly technical individuals responsible for enterprise\\nwide data platforms. The successful candidate will positively contribute in the\\nday-to-day responsibilities of the team and will ensure SLAs are met in\\naccordance with the organizational objectives.\\n\\nS/he will work closely with their\\nteam members and data warehouse leadership to ensure that appropriate technical\\nand analytical solutions are provided and to meet desired goals.\\n\\nPRINCIPAL DUTIES AND RESPONSIBILITIES:\\nResponsible for daily, weekly and monthly execution\\nand monitoring of all scheduled database jobs.\\n\\nPerforms issue assessments and follow appropriate\\ntroubleshooting steps in line with departmental standards and procedures as\\nwell as industry best practices.\\n\\nPerforms regular file and data archival and data purge\\nsteps as scheduled or as deemed necessary.\\n\\nRegularly reviews and proposes updates to current\\nstandards and processes to align them with changing organizational policy and\\nprocedures or with industry best practices.\\n\\nEnsures parity between development, test and\\nproduction environments. Performs intra-platform synchronization analysis to\\ngenerate automated methods of keeping platforms in sync.\\n\\nAdministers, maintains and supports internal systems,\\nsoftware and tools utilized by the team, including, but not limited to, version\\ncontrol, change management, and support ticketing.\\n\\nAble to move large amounts of data in files or within\\ndatabase tables using common data transfer or ETL tools such as Microsoft SSIS.\\n\\nResponsible for the upkeep, configuration, and\\nreliable operation of systems. Accountable to ensure that the uptime, performance,\\nresources, and security of the systems he or she manages meet the needs of the\\nusers and established SLAs.\\n\\nMonitors the systems daily and responds to\\navailability, security or usability concerns within the pre-agreed-upon SLA\\nwindows\\n\\nAnalyzes system logs, identifies and follows ways to\\nbe proactive in identifying potential issues with systems.\\n\\nApplies system updates, patches, and configuration\\nchanges.\\n\\nInstalls and configures new versions of the system\\nsoftware.\\n\\nFor the systems s/he is responsible for, adds, removes\\nor updates user account, security or access information. Clearly documents all\\nsteps followed for aforementioned actions.\\n\\nHas responsibility for documenting the configuration\\nof the system.\\n\\nPerforms system performance tuning.\\n\\nTroubleshoots any reported problems, in a fast-paced\\nenvironment under constraints and stress.\\n\\nAble to communicate and coordinate tasks effectively\\nwith other team members as well as end users.\\n\\nManages and maintains relationships with vendors and\\nteams from other parts of the organization to provide seamless support to end\\nusers on the systems he or she is responsible for.\\n\\nCommunicates technical/complex information well both\\nverbally and in writing. Answers technical queries and assists team members and\\nusers whenever needed.\\n\\nAble to establish and maintain cooperation,\\nunderstanding, trust and credibility.\\n\\nAble to perform multiple tasks concurrently and\\neffectively.\\n\\nMaintains technical knowledge by attending educational\\nworkshops; reviewing publications; establishing personal networks;\\nparticipating in technical societies.\\n\\nMaintains client and user confidence and protects\\noperations by keeping sensitive information confidential.\\n\\nQualifications\\n\\nQUALIFICATIONS:\\nBachelor degree required in\\nComputer Science or directly related field\\n\\n2+ years of experience\\nrequired in healthcare/data warehouse or directly related experience required\\n\\nincluding:\\n·\\n\\nExperience\\nin maintaining, administering and supporting various business critical systems\\npreferably database platforms, source control systems (Team Foundation Server\\nis highly preferred) and issue/support tracking/ticketing systems.\\n\\n·\\n\\nExperience\\nin using an industry-standard data transfer or ETL tool (Microsoft SSIS is\\nhighly preferred).\\n\\nSystem Administration or System Engineer certification\\nin any one of the Microsoft platforms, components or services is preferred.\\n\\nKnowledge of one or more programming or scripting\\nlanguages (C#, Java, PowerShell, etc.) and experience with custom software\\ndevelopment to assist in internal process automation is preferred.\\n\\nMay need to train staff in following best practices in\\nhis or her area of responsibility.\\n\\nResponsibilities sometimes require working evenings\\nand weekends, sometimes with little advanced notice.\\n\\nSKILLS/ ABILITIES/ COMPETENCIES REQUIRED:\\nSupports and demonstrates the\\nvalues of the Massachusetts General Hospital and the Massachusetts Physicians\\nOrganization by conducting activities in an ethical manner with integrity,\\nhonesty, and confidentiality.\\n\\nShows a positive,\\nopen-minded, and can-do attitude.\\n\\nDemonstrates a team\\norientation, willingness and enthusiasm to collaborate with others.\\n\\nFollows through on\\ncommitments and achieves desired results.\\n\\nExhibits sound judgment,\\nobtains the facts, examines options, gains support, and achieves positive\\noutcomes\\n\\nDemonstrates continuing\\nprofessional growth in knowledge and skills through education, goal setting and\\npersonal development\\n\\nConducts self in a professional manner and\\ndemonstrates an attitude which inspires staff to a high level of\\nprofessionalism\\n\\nHighly\\nself-motivated/disciplined, performs role with minimal supervision, notice or\\ndirection to identify and resolve problems and to complete work\\n\\nAbility to interact with\\npeople from all organizational levels and builds consensus through negotiation\\nand diplomacy\\n\\nAbility to present to multiple levels of staff from\\nVPs, to EDs, to ADs, to Managers, to Clinical Providers, to Billing Managers to\\nfront desk staff\\n\\nAbility to understand the work environment and competing\\npriorities in conjunction with developing/meeting project goals\\n\\nStrong analytical and problem\\nsolving skills\\n\\nStrong written and verbal\\ncommunication skills\\n\\nAbility to plan and prioritize tasks accordingly\\n\\nAbility to manage multiple tasks and issues simultaneously\\n\\nStrong ability to pay attention to detail\\n\\nProficiency in Microsoft\\nOffice suite (Excel, Word, Access, Outlook) required, EPIC (or similar)\\nsystem(s) preferred\\n\\nEEO Statement\\n\\nEEO Statement: Massachusetts General Hospital is an Equal Opportunity Employer. By embracing diverse skills, perspectives and ideas, we choose to lead. Applications from protected veterans and individuals with disabilities are strongly encouraged.\\n\\nPrimary Location\\n\\n:\\n\\nMA-Charlestown-529 Main - MGH\\n\\nWork Locations\\n\\n:\\n\\n529 Main - MGH\\n\\n529 Main Street\\n\\nCharlestown\\n\\n02129\\n\\nJob\\n\\n:\\n\\nIT/Health IT/Informatics - Other\\n\\nOrganization\\n\\n:\\n\\nMassachusetts General Hospital(MGH)\\n\\nSchedule\\n\\n:\\n\\nFull-time\\n\\nStandard Hours\\n\\n:\\n\\n40\\n\\nShift\\n\\n:\\n\\nDay Job\\n\\nPosted Shift Description\\n\\n:\\n\\nThe hours are usually Monday through Friday 8:00 AM to 5:00 PM but vary per the demands of this exempt salaried position.\\n\\nEmployee Status\\n\\n:\\n\\nRegular\\n\\nRecruiting Department\\n\\n:\\n\\nMGPO Finance\\n\\nJob Posting\\n\\n:\\n\\nMar 12, 2018\\nPartners HealthCare - \\n28 minutes ago',\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=6d68aeaccd78f455',\n",
       "  'location': 'Charlestown, MA',\n",
       "  'title': 'Data Warehouse Analyst'},\n",
       " 'bb857e181493a30e': {'company': 'Commonwealth of Massachusetts',\n",
       "  'jd': \"The Executive Office of Labor and Workforce Development (EOLWD) is responsible for five agencies and departments under the organization. EOLWD and its agencies are committed to developing a world-class, highly skilled labor force to support business growth and innovation in the Commonwealth.\\n\\nRESPONSIBILITIES\\nStrategy & Planning\\n\\nCreate short-term tactical solutions to achieve long-term objectives and an overall data management roadmap\\nAssist with assessing and determining governance, stewardship, and frameworks for managing data across the organization\\nEnsure design governance across projects, applications and infrastructure\\nEstablish methods and procedures for tracking data quality, completeness, redundancy, and improvement\\nConduct data capacity planning, life cycle, duration, usage requirements, feasibility studies, and other tasks\\nDevelop and deliver long-term strategic goals for data integration standards in conjunction with data users, department managers, clients, and other key stakeholders\\nEnsure that data strategies and architectures are in regulatory compliance\\nOperational Management\\n\\nDevelop integration process data flows and data mapping analyses\\nAddress data-related problems in regards to systems integration, compatibility, and multiple-platform integration\\nDevelop and promote data integration methodologies and standards\\nAct as an advocate of data integration and management, including coaching, training, and career development to staff\\nDevelop and implement key components as needed to create testing criteria in order to guarantee the fidelity and performance of data architecture\\nIdentify and develop opportunities for data reuse, migration, or retirement of systems\\nAssist with the selection and implementation of the appropriate methodologies, standards, tools, software, applications, and systems to support data technology goals\\nOversee the mapping of data sources, data movement, interfaces, and analytics, with the goal of ensuring data quality\\nRequired Experience\\n\\nMinimum of 4 years Oracle ODI experience\\n5-8 years overall experience in Data Integration, Data Architecture, Data Modeling, and implementation\\nMinimum of 5 years of full lifecycle data warehousing experience\\nImplementation of ODI interfaces and scenarios for extracting and loading data from a variety of data sources/targets including, Relational Database Management servers (including Oracle RDBMS, flat files (including CSV, Excel, & XML file formats), and web services (SOAP, WS-I Security)\\nExperience with Set up, configuring and administration of ODI according to requirements\\nBI knowledge a requirement 5 year in BI from ETL perspective\\nDesign experience of the detailed ETL architecture, including agents, scenarios, packages, data mapping, data extractions, transformations and validations (this ETL design and implementation should include stand-alone and Java EE agents, ODI data services, ODI Console, ODI studio, and other appropriate development tools)\\nAbility to observe steps and ascertain success of step or failure and root cause of step(s)\\nExperience in Master Data Management and Meta Data Management\\nExperience in Dimensional Modeling\\nSalary placement is determind by years of experience and education directly related to the position and the Human Resources Division's recruiting guidelines. In the case of a promotional opportunity, the salary provisions of the applicable bargaining agreement will be utilized for placement within the salary range.\\n\\nQualifications\\n\\nFirst consideration will be given to those applicants that apply within the first 14 days.\\n\\nMinimum Entrance Requirements:\\nApplicants must have at least (A) four years of full-time, or equivalent part-time, professional experience in electronic data processing of which (B) at least two years must have been in work in which the major duties included computer systems analysis, or (C) any equivalent combination of the required experience and the substitutions below.\\n\\nSUBSTITUTIONS:\\nI. An Associate's degree with a major in the field of data processing or computer programming may be substituted for a maximum of one year of the required (A) experience.*\\n\\nII. A Bachelor's degree with a major in the field of data processing or computer and/or information science may be substituted for a maximum of two years of the required (A) experience.*\\n\\nIII. A Graduate degree with a major in the field of data processing or computer and/or information science may be substituted for a maximum of two years of the required (A) experience.*\\n\\nIV. A diploma for completion of a two year full-time, or equivalent part-time, program in a recognized non-degree granting business or vocational/technical school above the high school level with a major in the field of computer programming may be substituted for a maximum of one year of the required (A) experience.*\\n\\nV. An official transcript from a recognized business or vocational/ technical school as evidence of completion of a program consisting of at least 650 hours of instruction in the field of computer programming may be substituted for a maximum of one year of the required (A) experience.\\n\\nVI. Graduation from the data processing course of a recognized vocational/technical high school may be substituted for a maximum of one year of the required (A) experience.\\n\\n\\nEducation toward such a degree or diploma will be prorated on the basis of the proportion of the requirements actually completed.\\n\\nNOTE: No substitution will be allowed for more than two years of the required (A) experience.\\n\\nNOTE: No substitution will be allowed for the two years of the required (B) experience.\\n\\nSpecial Requirements: None.\\nCommonwealth of Massachusetts - \\n2 hours ago\",\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=bb857e181493a30e',\n",
       "  'location': 'Boston, MA',\n",
       "  'title': 'ODI Data Warehouse Administrator'},\n",
       " 'cb14becd283b42c5': {'company': 'WGBH Educational Foundation',\n",
       "  'jd': \"Reporting to the Marketing Manager, the Data Marketing Specialist would be responsible for:\\n\\nManage all data inquiries and query requests from the Membership Marketing team, providing output files for all direct mail and telemarketing campaigns for WGBH, WGBY, WCAI and other client stations.\\nAct as the primary point of contact for all data related issues within the Membership Marketing team, escalating issues as needed to the Tech Solutions team\\nDesign, develop and implement segmentations, queries and basic data analysis from database schemas\\nValidate integrity and accuracy of all data this position provides\\nWorking with the Marketing Managers and Program Marketing Coordinators, provide mailing lists, calling lists, file layouts, segmentation counts and projections, criteria selection details, query pull dates, campaign codes and more.\\nStrictly adhere to multiple deadlines\\nReport regularly to the Membership Marketing Manager on query performance, successful implementation of segmentation strategies, and system related issues.\\nPrepare and conduct ad hoc trainings as needed\\nMaintain an online filing system for all selection rules, data flows, and interactions.\\nCreate, maintain and share a detailed calendar of projects and deadlines\\nMaintain updated documentation on all processes related to respective project areas.\\n\\nSkills Required\\n\\nKnowledge of Salesforce, Red Point or other relational database required. Proficiency with Python and Microsoft Excel are essential. The ability to work in a fast-paced environment overseeing multiple projects simultaneously while meeting deadlines is essential, along with proven administrative and organizational skills, extreme attention to detail, and willingness to adapt to changing responsibilities. Candidates must have above average mathematical aptitude, excellent spreadsheet and statistical skills, and be highly computer literate.\\n\\nEducational Requirements\\n\\nBachelor's degree or equivalent years work experience preferred.\\nWGBH Educational Foundation - \\n1 hour ago\",\n",
       "  'job_url': 'http://www.indeed.com/m/viewjob?jk=cb14becd283b42c5',\n",
       "  'location': 'Boston, MA',\n",
       "  'title': 'Data Marketing Specialist'}}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
